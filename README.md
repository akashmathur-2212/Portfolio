# ğŸ”¬ Generative AI Applications â€“ Project Portfolio ğŸ“

Welcome to my personal portfolio showcasing hands-on projects in the Generative AI space. These projects explore the full GenAI lifecycle including coding LLMs from scratch using PyTorch, synthetic data generation, fine-tuning, evaluation, and cloud deployment.

Each repository is backed by practical use cases, best practices, and open-source tools.

---

## ğŸª¢ Finetuning Toolkit

A comprehensive guide and codebase for **fine-tuning Large Language Models (LLMs)** using leading open-source frameworks. This project explores parameter-efficient fine-tuning (PEFT), QLoRA, and model adapters to customize LLMs for downstream tasks.

| Description | Link |
|------------|------|
| - ğŸ¤— [Hugging Face PEFT](https://huggingface.co/docs/peft/index) <br> - ğŸ¦¥ [Unsloth: Fast QLoRA](https://github.com/unslothai/unsloth) <br> - ğŸ¦ [Axolotl: Fine-tuning Framework](https://github.com/OpenAccess-AI-Collective/axolotl) | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/llm-finetuning) |

---

## ğŸ§ª Evaluation Toolkit

This project offers a robust evaluation stack for LLM-based applications, using both retrieval-based metrics and **LLM-as-a-Judge** techniques for scoring output quality across relevance, coherence, and faithfulness.

| Description | Link |
|------------|------|
| - ğŸ“ˆ [RAGAS: RAG Evaluation](https://docs.ragas.io/en/stable/) <br> - âš–ï¸ [LLM-as-a-Judge](https://arxiv.org/abs/2411.15594) | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/llm-evaluation) |

---

## ğŸ§  Synthetic Data Generation Toolkit

This toolkit helps generate **high-quality synthetic datasets** (e.g., Q&A pairs, instructions) for LLM evaluation, training, or augmentation. It leverages Self-Instruct and feedback loops for dataset diversity and domain control.

| Description | Link |
|------------|------|
| - ğŸ“š [Distilabel: Synthetic Data Engine](https://distilabel.argilla.io/latest/) <br> - ğŸ“Œ Self-Instruct methodology | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/synthetic-data-generation) |

---

## ğŸ› ï¸ Coding LLMs from Scratch

Explore the internals of transformer models by building LLM components **from scratch in PyTorch**. This educational project includes self-attention, positional encoding, and training logic.

| Description | Link |
|------------|------|
| Build your own LLM in PyTorch, from embeddings to transformer blocks | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/transformers_from_scratch) |

---

## ğŸ” Advanced RAG Applications

This project showcases **Retrieval-Augmented Generation (RAG)** with structured and unstructured data. It demonstrates advanced RAG use cases with LangChain and LlamaIndex, including tool use and multi-step retrieval.

| Description | Link |
|------------|------|
| Advanced RAG pipelines with multimodal inputs and agentic reasoning | [View Repository](https://github.com/akashmathur-2212/LLMs-playground/tree/main) |

---

## â˜ï¸ Model Serving and Deployment

Production-grade workflows for **LLM model serving, orchestration, and cloud deployment** using serverless architecture (e.g., AWS Lambda, API Gateway). Includes CI/CD and scalable endpoint setup.

| Description | Link |
|------------|------|
| Cloud-native deployment of LLM inference pipelines | [View Repository](https://github.com/akashmathur-2212/aws-serverless-workflows) |

---

## ğŸ‘¨â€ğŸ’» Author

**Akash Mathur**  
Senior Machine Learning Engineer, Amsterdam, Netherlands  
Building secure, scalable, and intelligent systems.

[LinkedIn](https://www.linkedin.com/in/akashmathur22/) â€¢ [GitHub](https://github.com/akashmathur-2212)

---

Feel free to explore, fork, and contribute!

