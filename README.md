# 🔬 Generative AI Applications – Project Portfolio 📍

Welcome to my personal portfolio showcasing hands-on projects in the Generative AI space. These projects explore the full GenAI lifecycle including coding LLMs from scratch using PyTorch, synthetic data generation, fine-tuning, evaluation, and cloud deployment.

Each repository is backed by practical use cases, best practices, and open-source tools.

---

## 🪢 Finetuning Toolkit

A comprehensive guide and codebase for **fine-tuning Large Language Models (LLMs)** using leading open-source frameworks. This project explores parameter-efficient fine-tuning (PEFT), QLoRA, and model adapters to customize LLMs for downstream tasks.

| Description | Link |
|------------|------|
| - 🤗 [Hugging Face PEFT](https://huggingface.co/docs/peft/index) <br> - 🦥 [Unsloth: Fast QLoRA](https://github.com/unslothai/unsloth) <br> - 🦎 [Axolotl: Fine-tuning Framework](https://github.com/OpenAccess-AI-Collective/axolotl) | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/llm-finetuning) |

---

## 🧪 Evaluation Toolkit

This project offers a robust evaluation stack for LLM-based applications, using both retrieval-based metrics and **LLM-as-a-Judge** techniques for scoring output quality across relevance, coherence, and faithfulness.

| Description | Link |
|------------|------|
| - 📈 [RAGAS: RAG Evaluation](https://docs.ragas.io/en/stable/) <br> - ⚖️ [LLM-as-a-Judge](https://arxiv.org/abs/2411.15594) | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/llm-evaluation) |

---

## 🧠 Synthetic Data Generation Toolkit

This toolkit helps generate **high-quality synthetic datasets** (e.g., Q&A pairs, instructions) for LLM evaluation, training, or augmentation. It leverages Self-Instruct and feedback loops for dataset diversity and domain control.

| Description | Link |
|------------|------|
| - 📚 [Distilabel: Synthetic Data Engine](https://distilabel.argilla.io/latest/) <br> - 📌 Self-Instruct methodology | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/synthetic-data-generation) |

---

## 🛠️ Coding LLMs from Scratch

Explore the internals of transformer models by building LLM components **from scratch in PyTorch**. This educational project includes self-attention, positional encoding, and training logic.

| Description | Link |
|------------|------|
| Build your own LLM in PyTorch, from embeddings to transformer blocks | [View Repository](https://github.com/akashmathur-2212/Deep-Learning-with-PyTorch-HuggingFace/tree/main/transformers_from_scratch) |

---

## 🔍 Advanced RAG Applications

This project showcases **Retrieval-Augmented Generation (RAG)** with structured and unstructured data. It demonstrates advanced RAG use cases with LangChain and LlamaIndex, including tool use and multi-step retrieval.

| Description | Link |
|------------|------|
| Advanced RAG pipelines with multimodal inputs and agentic reasoning | [View Repository](https://github.com/akashmathur-2212/LLMs-playground/tree/main) |

---

## ☁️ Model Serving and Deployment

Production-grade workflows for **LLM model serving, orchestration, and cloud deployment** using serverless architecture (e.g., AWS Lambda, API Gateway). Includes CI/CD and scalable endpoint setup.

| Description | Link |
|------------|------|
| Cloud-native deployment of LLM inference pipelines | [View Repository](https://github.com/akashmathur-2212/aws-serverless-workflows) |

---

## 👨‍💻 Author

**Akash Mathur**  
Senior Machine Learning Engineer, Amsterdam, Netherlands  
Building secure, scalable, and intelligent systems.

[LinkedIn](https://www.linkedin.com/in/akashmathur22/) • [GitHub](https://github.com/akashmathur-2212)

---

Feel free to explore, fork, and contribute!

